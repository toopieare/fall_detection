{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2ep-q7k_5R-"
      },
      "source": [
        "# Sound classification with YAMNet\n",
        "\n",
        "YAMNet is a deep net that predicts 521 audio event [classes](https://github.com/tensorflow/models/blob/master/research/audioset/yamnet/yamnet_class_map.csv) from the [AudioSet-YouTube corpus](http://g.co/audioset) it was trained on. It employs the\n",
        "[Mobilenet_v1](https://arxiv.org/pdf/1704.04861.pdf) depthwise-separable\n",
        "convolution architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Install the dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python3 -m pip install tensorflow\n",
        "!pip install tensorflow-hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Bteu7pfkpt_f"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio\n",
        "from scipy.io import wavfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSVs3zRrrYmY"
      },
      "source": [
        "Load the Model from TensorFlow Hub.\n",
        "\n",
        "Note: to read the documentation just follow the model's [url](https://tfhub.dev/google/yamnet/1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "VX8Vzs6EpwMo"
      },
      "outputs": [],
      "source": [
        "# Load the model.\n",
        "model = hub.load('https://tfhub.dev/google/yamnet/1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "LizGwWjc5w6A"
      },
      "outputs": [],
      "source": [
        "## Add a method to verify and convert a loaded audio is on the proper sample_rate (16K), otherwise it would affect the model's results.\n",
        "def ensure_sample_rate(original_sample_rate, waveform,\n",
        "                       desired_sample_rate=16000):\n",
        "  \"\"\"Resample waveform if required.\"\"\"\n",
        "  if original_sample_rate != desired_sample_rate:\n",
        "    desired_length = int(round(float(len(waveform)) /\n",
        "                               original_sample_rate * desired_sample_rate))\n",
        "    waveform = scipy.signal.resample(waveform, desired_length)\n",
        "  return desired_sample_rate, waveform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Wo9KJb-5zuz1"
      },
      "outputs": [],
      "source": [
        "from scipy.io import wavfile\n",
        "\n",
        "import wave\n",
        "\n",
        "def convert_pcm_to_wave(pcm_path=\"Fall1.pcm\"):\n",
        "  # Define parameters\n",
        "  wav_path = pcm_path.replace(\".pcm\", \".wav\")\n",
        "  channels = 1\n",
        "  sample_width = 2  # 2 bytes = 16-bit audio\n",
        "  frame_rate = 16000  # Hz\n",
        "\n",
        "  # Read raw PCM data\n",
        "  with open(pcm_path, 'rb') as pcmfile:\n",
        "      pcm_data = pcmfile.read()\n",
        "\n",
        "  # Write WAV file\n",
        "  with wave.open(wav_path, 'wb') as wavfile:\n",
        "      wavfile.setnchannels(channels)\n",
        "      wavfile.setsampwidth(sample_width)\n",
        "      wavfile.setframerate(frame_rate)\n",
        "      wavfile.writeframes(pcm_data)\n",
        "\n",
        "def get_embedding(file_path):\n",
        "  if file_path.endswith(\".pcm\"):\n",
        "    convert_pcm_to_wave(file_path)\n",
        "    file_path = file_path.replace(\".pcm\", \".wav\")\n",
        "  # Load the audio.\n",
        "  sample_rate, wav_data = wavfile.read(file_path, 'rb')\n",
        "  sample_rate, wav_data = ensure_sample_rate(sample_rate, wav_data)\n",
        "\n",
        "  # Show some basic information about the audio.\n",
        "  duration = len(wav_data)/sample_rate\n",
        "  # print(f'Sample rate: {sample_rate} Hz')\n",
        "  # print(f'Total duration: {duration:.2f}s')\n",
        "  # print(f'Size of the input: {len(wav_data)}')\n",
        "\n",
        "  # # Listening to the wav file.\n",
        "  # Audio(wav_data, rate=sample_rate)\n",
        "  # The `wav_data` needs to be normalized to values in `[-1.0, 1.0]` (as stated in the model's [documentation](https://tfhub.dev/google/yamnet/1)).\n",
        "  waveform = wav_data / tf.int16.max\n",
        "\n",
        "  # Run the model, check the output.\n",
        "  scores, embeddings, spectrogram = model(waveform)\n",
        "  embedding = np.array(tf.reduce_mean(embeddings, axis=0))\n",
        "  return embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCKXauUJnGgs"
      },
      "source": [
        "### Use Fall1,2,3,4,5.pcm and NoFall1,2,3,4,5.pcm as calibration data\n",
        "\n",
        "Ensure the folder Sounds exists within the same directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "mgL4y65Llb6m"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import re\n",
        "import os\n",
        "\n",
        "fall_pattern = re.compile(r\"Fall\\d+\\.pcm\")\n",
        "embeddings_fall = []\n",
        "AUDIO_DIR = \"Sounds\"\n",
        "for file in glob.glob(f\"{AUDIO_DIR}/Fall*.pcm\"):\n",
        "    filename = os.path.basename(file)\n",
        "    if fall_pattern.fullmatch(filename):\n",
        "        embedding = get_embedding(f\"{AUDIO_DIR}/{filename}\")\n",
        "        embeddings_fall.append(embedding)\n",
        "embeddings_fall = np.array(embeddings_fall)\n",
        "\n",
        "nofall_pattern = re.compile(r\"NoFall\\d+\\.pcm\")\n",
        "embeddings_nofall = []\n",
        "for file in glob.glob(f\"{AUDIO_DIR}/NoFall*.pcm\"):\n",
        "    filename = os.path.basename(file)\n",
        "    if nofall_pattern.fullmatch(filename):\n",
        "        embedding = get_embedding(f\"{AUDIO_DIR}/{filename}\")\n",
        "        embeddings_nofall.append(embedding)\n",
        "embeddings_nofall = np.array(embeddings_nofall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "WDJaUMGpm37L"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial import distance\n",
        "def detect_fall(file_path):\n",
        "  query = get_embedding(file_path)\n",
        "\n",
        "  accum_fall_distance = 0\n",
        "  for i in range(4):\n",
        "    accum_fall_distance += distance.cosine(query, embeddings_fall[i]) * .25\n",
        "\n",
        "  accum_nofall_distance = 0\n",
        "  for i in range(4):\n",
        "    accum_nofall_distance += distance.cosine(query, embeddings_nofall[i]) * .25\n",
        "\n",
        "  if accum_fall_distance < accum_nofall_distance:\n",
        "    return \"fall\"\n",
        "  else:\n",
        "    return \"no fall\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "W1-4uHZZfrdN",
        "outputId": "945fbb83-0242-4cda-e134-be7413040591"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'fall'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "detect_fall(\"output.wav\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "sfm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
